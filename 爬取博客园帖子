from bs4 import BeautifulSoup
import requests
from lxml import etree
url = 'https://www.cnblogs.com/'
now_url = url
headers = {
    'user-agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36'
}
num = 1
page = 1
while True:
    print(page)
    r=requests.get(now_url,headers).text
    index=etree.HTML(r)
    # print(index)
    tz_url = index.xpath('//div[@class="post_item_body"]/h3/a/@href')
    # print(tz_url)
    next_url = index.xpath('//div[@class="pager"]/a[last()]')
    # print(next_url)
    for i in tz_url:
        re=requests.get(i,headers).text
        html=etree.HTML(re)
        tz_title = html.xpath('//a[@id="cb_post_title_url"]/text()') #list
        # print(tz_title)
        tz_content = html.xpath('string(//*[@id="cnblogs_post_body"])')  #str


        with open('pky.csv','a+',encoding='utf-8')as file:
            # file.write(tz_title[0]+'\n')
            file.write(tz_content+'\n')
            file.write(i+'\n')
            file.write('*'*100+'\n')

        print('第{0}页第{1}篇帖子'.format(page,num))
        num+=1

        if next_url[0].xpath('text()')[0]=='Next >':
            now_url=url[:-1]+next_url[0].xpath('@href')[0]
            print(now_url)
            page+=1
            num=1
        else:
            break
